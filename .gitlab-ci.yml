variables:
  NSPECT_ID: NSPECT-K66V-JJ0K
  DOCKER_IMG: nvmetal-carbide

  APPLICATION_DOCKER_IMAGE: nvcr.io/nvidian/nvforge-devel/nvmetal-carbide
  ARTIFACTS_DOCKER_IMAGE_AARCH64: nvcr.io/nvidian/nvforge-devel/boot-artifacts-aarch64
  ARTIFACTS_DOCKER_IMAGE_X86_64: nvcr.io/nvidian/nvforge-devel/boot-artifacts-x86_64

  APPLICATION_DOCKER_IMAGE_PRODUCTION: nvcr.io/nvidian/nvforge/nvmetal-carbide
  ARTIFACTS_DOCKER_IMAGE_AARCH64_PRODUCTION: nvcr.io/nvidian/nvforge/boot-artifacts-aarch64
  ARTIFACTS_DOCKER_IMAGE_X86_64_PRODUCTION: nvcr.io/nvidian/nvforge/boot-artifacts-x86_64

  FF_USE_FASTZIP: "true" # enable fastzip - a faster zip implementation that also supports level configuration.
  ARTIFACT_COMPRESSION_LEVEL: default # can also be set to fastest, fast, slow and slowest. If just enabling fastzip is not enough try setting this to fastest or fast.
  CACHE_COMPRESSION_LEVEL: fastest
  TRANSFER_METER_FREQUENCY: 5s

  KANIKO_CACHE_ARGS: "--cache=false --cache-copy-layers=true --cache-ttl=24h"
  APT_CACHE_DIR: $CI_PROJECT_DIR/apt
  LOGNAME: root
  KEA_BIN_PATH: /usr/bin
  KEA_INCLUDE_PATH: /usr/include/kea

  CARGO_INCREMENTAL: 0
  CARGO_HOME: $CI_PROJECT_DIR/cargo
  NEED_HELM: "yes"

  #
  # Container Regsitries for intermediate containers (build & runtime), not for publishing.
  #
  CONTAINER_REGISTRY_AARCH64: "urm.nvidia.com/swngc-ngcc-docker-local/forge/carbide/arm64v8"
  CONTAINER_REGISTRY_X86_64: "urm.nvidia.com/swngc-ngcc-docker-local/forge/carbide/x86-64"

  # Canonical versions - will be overridden if you touch one of the dockerfiles that builds them
  #
  # How to update a build or runtime container.
  #
  # Make one commit where you update the Dockerfile in dev/docker.  Make an MR for it, it will build the new container and push it to urm in the MR.
  #
  # Next, *add* a commit to your MR where you update the relevant docker locations here.
  #
  # If you don't do the second step, merging to production will use the prior container.  I don't know how to solve this, but it's the way it was before
  #
  CONTAINER_BUILD_AARCH64: "urm.nvidia.com/swngc-ngcc-docker-local/forge/carbide/arm64v8/build-container:latest"
  CONTAINER_BUILD_X86_64: "urm.nvidia.com/swngc-ngcc-docker-local/forge/carbide/x86-64/build-container:latest"
  CONTAINER_RUNTIME_AARCH64: "urm.nvidia.com/swngc-ngcc-docker-local/forge/carbide/arm64v8/runtime-container:latest"
  CONTAINER_RUNTIME_X86_64: "urm.nvidia.com/swngc-ngcc-docker-local/forge/carbide/x86-64/runtime-container:latest"
  CONTAINER_BUILD_ARTIFACTS_AARCH64: "urm.nvidia.com/swngc-ngcc-docker-local/forge/carbide/arm64v8/build-artifacts-container:latest"
  CONTAINER_BUILD_ARTIFACTS_X86_64: "urm.nvidia.com/swngc-ngcc-docker-local/forge/carbide/x86-64/build-artifacts-container:latest"
  CONTAINER_ARTIFACTS_X86_64: "alpine:latest"
  CONTAINER_ARTIFACTS_AARCH64: "alpine:latest"

include:
  - project: "nvmetal/ci-tools/build-container-cocogitto"
    ref: main
    file:
      - defaults.gitlab-ci.yml
  - project: "nvmetal/gitlab-templates"
    ref: main
    file:
      - defaults.gitlab-ci.yml

prepare-ci:
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
      needs:
        - job: "lint:commit-merge-request"
    - if: $CI_PIPELINE_SOURCE != "merge_request_event"
#    - if: $CI_PIPELINE_SOURCE == "push"
#      needs:
#        - job: "lint:commit-push"
#
# Reenable this when we want to enforce commit ci post-mr
# 
lint:commit-push:
  rules:
    - when: never


build:
  rules:
    - when: never

build-push-helm:
  rules:
    - when: never

build-push-kustomize:
  rules:
    - when: never

notify-security-report:
  rules:
    - when: never

prepare-kustomize-for-scan:
  rules:
    - when: never

build-container:
  rules:
    - when: never

checkmarx-scan-csv:
  rules:
    - when: never

checkov-scan:
  rules:
    - when: never

container-scan:
  rules:
    - when: never

pulse-open-source:
  rules:
    - when: never

export-docker-json-config:
  when: always

#
# Build the container that builds our software
#
build-build-container-x86_64:
  stage: build
  needs:
    - job: prepare-ci
      optional: false
  extends: build-container
  variables:
    DOCKER_FILE: $CI_PROJECT_DIR/dev/docker/Dockerfile.build-container-x86_64
    BUILD_DOCKER_IMAGE: urm.nvidia.com/swngc-ngcc-docker-local/forge/$CI_PROJECT_NAME/x86-64/build-container
  after_script:
    - echo "CONTAINER_BUILD_X86_64=$CONTAINER_REGISTRY_X86_64/build-container:$VERSION" > build-container-x86_64.env
    - echo "CONTAINER_BUILD_X86_64_WAS_BUILT=true" >> build-container-x86_64.env
  rules:
    - if: $CI_COMMIT_MESSAGE =~ /ci-rebuild-base-containers/
    - changes:
        - dev/docker/Dockerfile.build-container-x86_64
  artifacts:
    reports:
      dotenv: build-container-x86_64.env

#
# ARM version uses kaniko instead of extending build-container because devops-tools doesn't have an ARM version
#
build-build-container-aarch64:
  stage: build
  needs:
    - job: prepare-ci
      optional: false
  image:
    name: gcr.io/kaniko-project/executor:debug
    entrypoint: [""]
  variables:
    DOCKER_FILE: $CI_PROJECT_DIR/dev/docker/Dockerfile.build-container-aarch64
    BUILD_DOCKER_IMAGE: urm.nvidia.com/swngc-ngcc-docker-local/forge/$CI_PROJECT_NAME/arm64v8/build-container
  before_script: |
    mkdir -p /kaniko/.docker
    echo "$DOCKER_AUTH_CONFIG" > /kaniko/.docker/config.json
  script: |
    set -xeuo pipefail
    /kaniko/executor --context $CI_PROJECT_DIR/dev/docker --dockerfile $DOCKER_FILE --destination $BUILD_DOCKER_IMAGE:$VERSION
  tags:
    - aarch64
  rules:
    - if: $CI_COMMIT_MESSAGE =~ /ci-rebuild-base-containers/
    - changes:
        - dev/docker/Dockerfile.build-container-aarch64
  after_script:
    - echo "CONTAINER_BUILD_AARCH64=$CONTAINER_REGISTRY_AARCH64/build-container:$VERSION" > build-container-aarch64.env
    - echo "CONTAINER_BUILD_AARCH64_WAS_BUILT=true" >> build-container-aarch64.env
  artifacts:
    reports:
      dotenv: build-container-aarch64.env

#
# Build the container that builds our software
#
build-artifacts-build-container-x86_64:
  stage: build
  needs:
    - job: prepare-ci
      optional: false
  extends: build-container
  variables:
    DOCKER_FILE: $CI_PROJECT_DIR/dev/docker/Dockerfile.build-artifacts-container-x86_64
    BUILD_DOCKER_IMAGE: urm.nvidia.com/swngc-ngcc-docker-local/forge/$CI_PROJECT_NAME/x86-64/build-artifacts-container
  after_script:
    - echo "CONTAINER_BUILD_ARTIFACTS_X86_64=$CONTAINER_REGISTRY_X86_64/build-artifacts-container:$VERSION" > build-artifacts-container-x86_64.env
    - echo "CONTAINER_BUILD_ARTIFACTS_X86_64_WAS_BUILT=true" >> build-artifacts-container-x86_64.env
  rules:
    - if: $CI_COMMIT_MESSAGE =~ /ci-rebuild-base-containers/
    - changes:
        - dev/docker/Dockerfile.build-artifacts-container-x86_64
  artifacts:
    reports:
      dotenv: build-artifacts-container-x86_64.env

#
# ARM version uses kaniko instead of extending build-container because devops-tools doesn't have an ARM version
#
build-artifacts-build-container-aarch64:
  stage: build
  needs:
    - job: prepare-ci
      optional: false
  image:
    name: gcr.io/kaniko-project/executor:debug
    entrypoint: [""]
  variables:
    DOCKER_FILE: $CI_PROJECT_DIR/dev/docker/Dockerfile.build-artifacts-container-aarch64
    BUILD_DOCKER_IMAGE: urm.nvidia.com/swngc-ngcc-docker-local/forge/$CI_PROJECT_NAME/arm64v8/build-artifacts-container
  before_script: |
    mkdir -p /kaniko/.docker
    echo "$DOCKER_AUTH_CONFIG" > /kaniko/.docker/config.json
  script: |
    set -xeuo pipefail
    /kaniko/executor --context $CI_PROJECT_DIR/dev/docker --dockerfile $DOCKER_FILE --destination $BUILD_DOCKER_IMAGE:$VERSION
  tags:
    - aarch64
  rules:
    - if: $CI_COMMIT_MESSAGE =~ /ci-rebuild-base-containers/
    - changes:
        - dev/docker/Dockerfile.build-artifacts-container-aarch64
  after_script:
    - echo "CONTAINER_BUILD_ARTIFACTS_AARCH64=$CONTAINER_REGISTRY_AARCH64/build-artifacts-container:$VERSION" > build-artifacts-container-aarch64.env
    - echo "CONTAINER_BUILD_ARTIFACTS_AARCH64_WAS_BUILT=true" >> build-artifacts-container-aarch64.env
  artifacts:
    reports:
      dotenv: build-artifacts-container-aarch64.env

#
# Build the container that will host the finalized carbide code.
#
build-runtime-container-x86_64:
  stage: build
  needs:
    - job: prepare-ci
      optional: false
  extends: build-container
  variables:
    DOCKER_FILE: $CI_PROJECT_DIR/dev/docker/Dockerfile.runtime-container-x86_64
    BUILD_DOCKER_IMAGE: urm.nvidia.com/swngc-ngcc-docker-local/forge/$CI_PROJECT_NAME/x86-64/runtime-container
  rules:
    - if: $CI_COMMIT_MESSAGE =~ /ci-rebuild-base-containers/
    - changes:
        - dev/docker/Dockerfile.runtime-container-x86_64
  after_script:
    - echo "CONTAINER_RUNTIME_X86_64=$CONTAINER_REGISTRY_X86_64/runtime-container:$VERSION" > runtime-container-x86_64.env
    - echo "CONTAINER_RUNTIME_X86_64_WAS_BUILT==true" >> runtime-container-x86_64.env
  artifacts:
    reports:
      dotenv: runtime-container-x86_64.env

#
# ARM version uses kaniko instead of extending build-container because devops-tools doesn't have an ARM version
#
build-runtime-container-aarch64:
  stage: build
  needs:
    - job: prepare-ci
      optional: false
  variables:
    DOCKER_FILE: $CI_PROJECT_DIR/dev/docker/Dockerfile.runtime-container-aarch64
    BUILD_DOCKER_IMAGE: urm.nvidia.com/swngc-ngcc-docker-local/forge/$CI_PROJECT_NAME/arm64v8/runtime-container
  tags:
    - aarch64
  script: /bin/true
  rules:
    - when: never # TODO - we don't run carbide on ARM yet
#    - if: $CI_COMMIT_MESSAGE =~ /ci-rebuild-base-containers/
#    - changes:
#        - dev/docker/Dockerfile.runtime-container-aarch64
  after_script:
    - echo "CONTAINER_RUNTIME_AARCH64=$CONTAINER_REGISTRY_AARCH64/runtime-container:$VERSION" > runtime-container-aarch64.env
    - echo "CONTAINER_RUNTIME_AARCH64_WAS_BUILT=true" >> runtime-container-aarch64.env
  artifacts:
    reports:
      dotenv: runtime-container-aarch64.env

#
# When a new build/runtime/artifacts container is built, and we're on the
# trunk/main branch, then make sure we tag it with 'latest' so that subsequent
# jobs will use it.
#
tag-build-and-runtime-containers:
  stage: publish
  image:
    name: gcr.io/go-containerregistry/crane:debug
    entrypoint: [""]
  needs:
    - job: prepare-ci
      optional: false
    - job: export-docker-json-config
      optional: false
    - job: build-build-container-x86_64
      optional: true
    - job: build-build-container-aarch64
      optional: true
    - job: build-runtime-container-x86_64
      optional: true
    - job: build-runtime-container-aarch64
      optional: true
    - job: build-artifacts-build-container-x86_64
      optional: true
    - job: build-artifacts-build-container-aarch64
      optional: true
  allow_failure: true
  before_script: |
    mkdir -p /root/.docker
    cp .docker/config.json /root/.docker/config.json
  script: |
    set -xeuo pipefail

    if [ ! -z "${CONTAINER_BUILD_X86_64_WAS_BUILT:-}" ]; then
      crane copy "${CONTAINER_BUILD_X86_64}" "${CONTAINER_REGISTRY_X86_64}/build-container:latest"
    fi

    if [ ! -z "${CONTAINER_BUILD_AARCH64_WAS_BUILT:-}" ]; then
      crane copy "${CONTAINER_BUILD_AARCH64}" "${CONTAINER_REGISTRY_AARCH64}/build-container:latest"
    fi

    if [ ! -z "${CONTAINER_BUILD_ARTIFACTS_X86_64_WAS_BUILT:-}" ]; then
      crane copy "${CONTAINER_BUILD_ARTIFACTS_X86_64}" "${CONTAINER_REGISTRY_X86_64}/build-artifacts-container:latest"
    fi

    if [ ! -z "${CONTAINER_BUILD_ARTIFACTS_AARCH64_WAS_BUILT:-}" ]; then
      crane copy "${CONTAINER_BUILD_ARTIFACTS_AARCH64}" "${CONTAINER_REGISTRY_AARCH64}/build-artifacts-container:latest"
    fi

    if [ ! -z "${CONTAINER_RUNTIME_X86_64_WAS_BUILT:-}" ]; then
      crane copy "${CONTAINER_RUNTIME_X86_64}" "${CONTAINER_REGISTRY_X86_64}/runtime-container:latest"
    fi

    if [ ! -z "${CONTAINER_RUNTIME_AARCH64_WAS_BUILT:-}" ]; then
      crane copy  "${CONTAINER_RUNTIME_AARCH64}" "${CONTAINER_REGISTRY_AARCH64}/runtime-container:latest"
    fi

  rules:
    - if: $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH || $CI_COMMIT_MESSAGE =~ /ci-run-complete-pipeline/

#
# Build the final container that releases our code
#
build-release-container-x86_64:
  stage: build
  extends: build-push-container
  needs:
    - job: prepare-ci
      optional: false
    - job: build-build-container-x86_64
      optional: true
    - job: build-runtime-container-x86_64
      optional: true
  variables:
    DOCKER_FILE: $CI_PROJECT_DIR/dev/docker/Dockerfile.release-container-x86_64
  script:
    - export VAULT_TOKEN="$(vault write -field=token $VAULT_JWT_PATH role=$VAULT_JWT_ROLE jwt=$CI_JOB_JWT)"
    - export GROUP_ACCESS_TOKEN=$(vault kv get -field GROUP_ACCESS_TOKEN secrets/forge/tokens)
    - docker build -t intermediate-container-$CI_COMMIT_SHORT_SHA -f $DOCKER_FILE --build-arg VERSION=$VERSION --build-arg CI_COMMIT_SHORT_SHA=$CI_COMMIT_SHORT_SHA --build-arg CONTAINER_RUNTIME_X86_64=$CONTAINER_RUNTIME_X86_64 --build-arg CONTAINER_BUILD_X86_64=$CONTAINER_BUILD_X86_64 .
    - |
        set -euo pipefail
        if test "$DEPLOY_BUILT_CONTAINER" = "true"; then
          echo "Deploying build container: intermediate-container-$CI_COMMIT_SHORT_SHA to $APPLICATION_DOCKER_IMAGE:$VERSION"
          docker tag "intermediate-container-$CI_COMMIT_SHORT_SHA" "$APPLICATION_DOCKER_IMAGE:$VERSION"
          docker push "$APPLICATION_DOCKER_IMAGE:$VERSION"
          docker rmi "$APPLICATION_DOCKER_IMAGE:$VERSION"
        else
          echo "Skipping deployment of intermediate-container-$CI_COMMIT_SHORT_SHA"
        fi
    - docker rmi intermediate-container-$CI_COMMIT_SHORT_SHA
  rules:
    - if: $CI_COMMIT_TAG || $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH || $CI_COMMIT_MESSAGE =~ /ci-run-complete-pipeline/
      variables:
        DEPLOY_BUILT_CONTAINER: "true"
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
      variables:
        DEPLOY_BUILT_CONTAINER: "false"

#
# Build the final container that releases our code
#
.build-boot-artifacts:
  stage: build
  variables:
    FORGE_CA: "prod"

build-boot-artifacts-x86_64:
  extends: .build-boot-artifacts
  needs:
    - job: prepare-ci
      optional: false
    - job: build-artifacts-build-container-x86_64
      optional: true
  image:
    name: $CONTAINER_BUILD_ARTIFACTS_X86_64
  script:
    - cargo make --cwd pxe build-boot-artifacts-x86_64-ci
  artifacts:
    paths:
      - pxe/static/blobs/internal/x86_64/ipxe.efi
      - target/debug/forge-admin-cli
      - target/debug/forge-scout
    when: always
    expire_in: 1 day

build-boot-artifacts-aarch64:
  extends: .build-boot-artifacts
  needs:
    - job: prepare-ci
      optional: false
    - job: build-artifacts-build-container-aarch64
      optional: true
  tags:
    - aarch64 # not shell because no mkosi aarch64 image
  image:
    name: $CONTAINER_BUILD_ARTIFACTS_AARCH64
  script:
    - cargo make --cwd pxe build-boot-artifacts-aarch64-ci
  artifacts:
    paths:
      - pxe/static/blobs/internal/aarch64/ipxe.efi
      - pxe/static/blobs/internal/aarch64/carbide.efi
      - pxe/static/blobs/internal/aarch64/carbide.root
      - target/debug/forge-admin-cli
      - target/debug/forge-scout
    when: always
    expire_in: 1 day

# This just builds the mkosi container and uses artifacts from a previous build
build-boot-artifacts-ephemeral-image-x86-64:
  extends: .build-boot-artifacts
  needs:
    - job: prepare-ci
      optional: false
    - job: build-boot-artifacts-x86_64
      optional: false
  dependencies:
    - build-boot-artifacts-x86_64
  tags:
    - shell # mkosi cannot run in docker :(
  image:
    name: $CONTAINER_BUILD_ARTIFACTS_AARCH64
  script:
    - cargo make --cwd pxe create-ephemeral-image-x86_64-ci
  after_script:
    - "sudo chown -R gitlab-runner: /home/gitlab-runner/builds/"
  artifacts:
    paths:
      - pxe/static/blobs/internal/x86_64/carbide.efi
      - pxe/static/blobs/internal/x86_64/carbide.root
      - pxe/static/blobs/internal/x86_64/qcow-imaging.efi
      - pxe/static/blobs/internal/x86_64/qcow-imaging
      - pxe/static/blobs/internal/x86_64/qcow-imaging.root
    when: always
    expire_in: 1 day

build-release-artifacts-x86_64:
  stage: build
  extends: build-push-container
  needs:
    - job: prepare-ci
      optional: false
    - job: build-boot-artifacts-x86_64
      optional: false
    - job: build-boot-artifacts-ephemeral-image-x86-64
      optional: false
  dependencies:
    - build-boot-artifacts-ephemeral-image-x86-64
    - build-boot-artifacts-x86_64
    - prepare-ci
  variables:
    DOCKER_FILE: $CI_PROJECT_DIR/dev/docker/Dockerfile.release-artifacts-x86_64
  script:
    - export VAULT_TOKEN="$(vault write -field=token $VAULT_JWT_PATH role=$VAULT_JWT_ROLE jwt=$CI_JOB_JWT)"
    - export GROUP_ACCESS_TOKEN=$(vault kv get -field GROUP_ACCESS_TOKEN secrets/forge/tokens)
    - docker build -t intermediate-artifacts-$CI_COMMIT_SHORT_SHA -f $DOCKER_FILE --build-arg VERSION=$VERSION --build-arg CI_COMMIT_SHORT_SHA=$CI_COMMIT_SHORT_SHA --build-arg CONTAINER_RUNTIME_X86_64=$CONTAINER_ARTIFACTS_X86_64 .
    - |
        set -euo pipefail
        if test "$DEPLOY_BUILT_CONTAINER" = "true"; then
          echo "Deploying build container: intermediate-artifacts-$CI_COMMIT_SHORT_SHA to $ARTIFACTS_DOCKER_IMAGE_X86_64:$VERSION"
          docker tag "intermediate-artifacts-$CI_COMMIT_SHORT_SHA" "$ARTIFACTS_DOCKER_IMAGE_X86_64:$VERSION"
          docker push "$ARTIFACTS_DOCKER_IMAGE_X86_64:$VERSION"
        else
          echo "Skipping deployment of intermediate-artifacts-$CI_COMMIT_SHORT_SHA"
        fi
  rules:
    - if: $CI_COMMIT_TAG || $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH || $CI_COMMIT_MESSAGE =~ /ci-run-complete-pipeline/
      variables:
        DEPLOY_BUILT_CONTAINER: "true"
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
      variables:
        DEPLOY_BUILT_CONTAINER: "false"

build-release-artifacts-aarch64:
  stage: build
  image:
    name: gcr.io/kaniko-project/executor:debug
    entrypoint: [""]
  tags:
    - x86_64 # The AARCH64 artifacts are still packaged into the X86_64 version of the image because we execute commands in it on an X86_64 host
  needs:
    - job: prepare-ci
      optional: false
    - job: export-docker-json-config
      optional: false
    - job: build-runtime-container-x86_64
      optional: true
    - job: build-boot-artifacts-aarch64
      optional: false
  dependencies:
    - build-boot-artifacts-aarch64
    - prepare-ci
    - export-docker-json-config
  variables:
    DOCKER_FILE: $CI_PROJECT_DIR/dev/docker/Dockerfile.release-artifacts-aarch64
  before_script: |
    mkdir -p /kaniko/.docker
    cp .docker/config.json /kaniko/.docker/config.json
  script: |
    set -euo pipefail
    if test "$DEPLOY_BUILT_CONTAINER" = "true"; then
      echo "Deploying container: $ARTIFACTS_DOCKER_IMAGE_AARCH64:$VERSION"

      # The AARCH64 artifacts are still packaged into the X86_64 version of the image because we execute commands in it on an X86_64 host
      /kaniko/executor --context $CI_PROJECT_DIR --dockerfile $DOCKER_FILE --build-arg "CI_COMMIT_SHORT_SHA=$CI_COMMIT_SHORT_SHA" --build-arg "CONTAINER_RUNTIME_AARCH64=$CONTAINER_ARTIFACTS_X86_64" --destination "$ARTIFACTS_DOCKER_IMAGE_AARCH64:$VERSION"
    else
      echo "Skipping deployment of $ARTIFACTS_DOCKER_IMAGE_AARCH64:$VERSION"

      # The AARCH64 artifacts are still packaged into the X86_64 version of the image because we execute commands in it on an X86_64 host
      /kaniko/executor --context $CI_PROJECT_DIR --dockerfile $DOCKER_FILE --build-arg "CI_COMMIT_SHORT_SHA=$CI_COMMIT_SHORT_SHA" --build-arg "CONTAINER_RUNTIME_AARCH64=$CONTAINER_ARTIFACTS_X86_64" --no-push
    fi
  rules:
    - if: $CI_COMMIT_TAG || $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH || $CI_COMMIT_MESSAGE =~ /ci-run-complete-pipeline/
      variables:
        DEPLOY_BUILT_CONTAINER: "true"
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
      variables:
        DEPLOY_BUILT_CONTAINER: "false"

promote-images-to-production:
  stage: publish
  image:
    name: $CONTAINER_BUILD_X86_64
  needs:
    - job: build-release-artifacts-aarch64
      optional: false
    - job: build-release-artifacts-x86_64
      optional: false
    - job: build-release-container-x86_64
      optional: false
  when: manual
  before_script: |
    mkdir -p /root/.docker
    cp .docker/config.json /root/.docker/config.json
  script: |
    set -euo pipefail
    crane copy $APPLICATION_DOCKER_IMAGE:$VERSION $APPLICATION_DOCKER_IMAGE_PRODUCTION:$VERSION
    crane copy $ARTIFACTS_DOCKER_IMAGE_AARCH64:$VERSION $ARTIFACTS_DOCKER_IMAGE_AARCH64_PRODUCTION:$VERSION
    crane copy $ARTIFACTS_DOCKER_IMAGE_X86_64:$VERSION $ARTIFACTS_DOCKER_IMAGE_X86_64_PRODUCTION:$VERSION
  rules:
    - if: $CI_PIPELINE_SOURCE != 'merge_request_event' || $CI_COMMIT_MESSAGE =~ /ci-run-complete-pipeline/

license-checks:
  stage: security
  image:
    name: $CONTAINER_BUILD_X86_64
  rules:
    - when: never
    - changes:
        - Cargo.lock
        - .license-config.yml
    - if: $CI_COMMIT_TAG
    - if: $CI_PIPELINE_SOURCE != 'merge_request_event'

pages:
  stage: doc
  needs:
    - job: export-docker-json-config
      optional: false
    - job: build-runtime-container-x86_64
      optional: true
    - job: build-boot-artifacts-aarch64
      optional: false
  image:
    name: $CONTAINER_BUILD_X86_64
  script:
    - cargo make book
  artifacts:
    paths:
      - public
  rules:
    - changes:
        - book/
    - if: $CI_COMMIT_TAG
    - if: $CI_PIPELINE_SOURCE != 'merge_request_event'
