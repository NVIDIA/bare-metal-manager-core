# Reliable state handling

Forge achieves "reliable state handling" for a variety of resources via a mechanism called the "state controller".

"Reliable" state handling means the resources can traverse through their lifecycle states even in the case of intermittent errors (e.g. a Host BMC or a dependent service is temporarily unavailable) due to automated periodic retries. It also means that the state handling is deterministic and free of race conditions.

Resources managed by State Controllers are:
- ManagedHost Lifecycle
- IB Partition Lifecycle
- Network Segment Lifecycle


The following [Video presentation](https://teams.microsoft.com/l/meetingrecap?driveId=b%21U2mBz7BMOE2wmplvgh67ZJGG25sJ7otPkDIq_O1Yrqh42Iv5vVMwQZHJCp83fSbf&driveItemId=01G3AEJXDITOYBFX6ENNFIDO6Y2CT5PV5G&sitePath=https%3A%2F%2Fnvidia-my.sharepoint.com%2F%3Av%3A%2Fp%2Faforgue%2FEWibsBLfxGtKgbvY0KfX16YBWjB8RxKw6xNJhonXckgyqA&fileUrl=https%3A%2F%2Fnvidia-my.sharepoint.com%2Fpersonal%2Faforgue_nvidia_com%2FDocuments%2FRecordings%2FForge%2520Brown%2520Bag%2520Series-20250507_093203-Meeting%2520Recording.mp4%3Fweb%3D1&iCalUid=040000008200E00074C5B7101A82E00807E905078ED257D473B8DB01000000000000000010000000B3A89BA6D3BC7B44876978CDFB3F944C&masterICalUid=040000008200E00074C5B7101A82E008000000008ED257D473B8DB01000000000000000010000000B3A89BA6D3BC7B44876978CDFB3F944C&threadId=19%3Ameeting_Nzc1YzZkZDQtMmE1Yy00ZTUzLWJiZGEtNzcyYjNkZWU1NWM4%40thread.v2&organizerId=d039ef74-33b4-40e5-a836-1743f3c5eba7&tenantId=43083d15-7273-40c1-b7db-39efd9ccc17a&callId=5c2076f5-e3c1-42d4-a3cf-06d03374ac70&threadType=Meeting&meetingType=Recurring&subType=RecapSharingLink_RecapCore) provides an intro into how state handling works in Forge.

The following bullet-points summarize the functionality:
- Carbide defines some generic interfaces for resources whose state need to be handled. The [StateHandler interface](https://gitlab-master.nvidia.com/nvmetal/carbide/-/blob/b5cc24ce7e2db21ca0c7dc576cab328d5a33013c/api/src/state_controller/state_handler.rs#L83-97) and the [IO interface](https://gitlab-master.nvidia.com/nvmetal/carbide/-/blob/b5cc24ce7e2db21ca0c7dc576cab328d5a33013c/api/src/state_controller/io.rs#L24-88). The handler implementation specifies how to transition between states, while IO defines how to load resources from the database and store them back there.
- The handler function gets executed periodically (typically every 30s) and is implemented in an idempotent fashion. That means that even if something fails intermittently, it will be automatically retried in the next iteration.
- The state handler is the only entity that directly changes the lifecycle state of a resource. And the only way to transition to a new state is by the handler function returning the new state as result.Other components like API handlers can only queue intents/requests (e.g. "I want to use this host as an instance", "I want to report a network status change",  "I want to report a health status change"). That prevents lots of race conditions.
- For hosts/machines - Forge biggest resource - [the implementation is here](https://gitlab-master.nvidia.com/nvmetal/carbide/-/blob/b5cc24ce7e2db21ca0c7dc576cab328d5a33013c/api/src/model/machine/mod.rs?page=2#L1024-1100). As one can observe when diving down the functions, it's basically a gigantic switch/case ("if this state, then wait for this signal, and go to the next"). Modelling states as Rust enums immensely helps here. It's impossible to ignore handling a particular state or substate. The compiler would complain. Top level host lifecycle state is defined here - and as you can see its very big. The states also all serialize into JSON values, which can be observed in the state history with admin tooling for each resource.
- There's state diagrams in the docs: [https://nvmetal.gitlab-master-pages.nvidia.com/carbide/architecture/state_machines/managedhost.html](https://nvmetal.gitlab-master-pages.nvidia.com/carbide/architecture/state_machines/managedhost.html)
- Every time the state handler runs it also generates a set of metrics for every resource it manages. That for example provides visibility into "what resource is in what state", but also "how long does it take to exit a state, where does exiting the state fail due to failures, and resource specific metrics like "what is the health of hosts". These are all visible on the [site dashboard](https://ngcobservability-grafana.thanos.nvidiangn.net/d/WzX_VErVk/forge-site?orgId=1&refresh=1m) - e.g. under the "Forge ManagedHosts, State Handling Performance, and Host Health" sections.
- Every state also has a SLA attached to it - a time in which we expect the resource to leave the state. That SLA is used to produce additional information in APIs ("is the resource in state for longer than SLA"), as well as in metrics and alerts (provides visibility into how many resources/hosts are stuck).
